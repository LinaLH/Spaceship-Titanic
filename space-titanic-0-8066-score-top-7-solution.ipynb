{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6720728d",
   "metadata": {
    "papermill": {
     "duration": 0.015849,
     "end_time": "2024-02-20T01:53:07.948738",
     "exception": false,
     "start_time": "2024-02-20T01:53:07.932889",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5700741f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:53:07.982156Z",
     "iopub.status.busy": "2024-02-20T01:53:07.981407Z",
     "iopub.status.idle": "2024-02-20T01:53:13.515474Z",
     "shell.execute_reply": "2024-02-20T01:53:13.514466Z"
    },
    "papermill": {
     "duration": 5.553875,
     "end_time": "2024-02-20T01:53:13.518211",
     "exception": false,
     "start_time": "2024-02-20T01:53:07.964336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valen\\AppData\\Local\\Temp\\ipykernel_15908\\4261108173.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split,GridSearchCV,cross_val_score,StratifiedKFold\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxgb\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcategory_encoders\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mce\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "#Space titanic competition 0.80664 Score\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,cross_val_score,StratifiedKFold\n",
    "import xgboost as xgb\n",
    "import category_encoders as ce\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score,f1_score, confusion_matrix\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.impute import SimpleImputer,KNNImputer\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e47892",
   "metadata": {
    "papermill": {
     "duration": 0.014884,
     "end_time": "2024-02-20T01:53:13.548367",
     "exception": false,
     "start_time": "2024-02-20T01:53:13.533483",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Let’s Start**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825b896a",
   "metadata": {
    "papermill": {
     "duration": 0.016028,
     "end_time": "2024-02-20T01:53:13.579509",
     "exception": false,
     "start_time": "2024-02-20T01:53:13.563481",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As you can see, after I loaded the dataset, I removed both the “Passenger Id” and “Name” columns. They are not going to provide any useful or important information to the prediction. Someone’s name or Id does not change the probability of being Transported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a14cb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:53:13.618107Z",
     "iopub.status.busy": "2024-02-20T01:53:13.617098Z",
     "iopub.status.idle": "2024-02-20T01:53:13.703504Z",
     "shell.execute_reply": "2024-02-20T01:53:13.702292Z"
    },
    "papermill": {
     "duration": 0.108756,
     "end_time": "2024-02-20T01:53:13.706567",
     "exception": false,
     "start_time": "2024-02-20T01:53:13.597811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/spaceship-titanic/train.csv\")\n",
    "\n",
    "#After loading the dataset, I dropped the \"PassengerId\" and the \"Name\" column.\n",
    "\n",
    "#But why? Knowing a passengers name or Id will not provide any usefull information to the model.\n",
    "\n",
    "#Someone named \"James\" or with a certain Id number will not have a greater or lower chance of surviving.\n",
    "\n",
    "#So, I just removed both columns.\n",
    "\n",
    "df.drop(columns=[\"PassengerId\",\"Name\"],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4fc692",
   "metadata": {
    "papermill": {
     "duration": 0.0206,
     "end_time": "2024-02-20T01:53:13.750455",
     "exception": false,
     "start_time": "2024-02-20T01:53:13.729855",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, we are going to discuss a fundamental step I came across after trying to improve my score a thousand times. This step relies on exploring the “Cabin” column. Notice that the rows on the “Cabin” column follow a specific pattern. Something like this: “A/5/S”, “C/1/S”, “F/7/P”. And I decided to investigate it. So, to make things simple I split the rows of the “Cabin” into three columns based on both slashes (”/”) of the rows. For example, the “A/5/S” row would be transformed into three new columns: The first one is named “cabin_code” referring to the character behind the first slash (A). The second one named “id_cabin” refers to the character behind the second slash (5). The third one named “cabin_sector” refers to the character after the second slash (S). And we end up with three new columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e29d5f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:53:13.783542Z",
     "iopub.status.busy": "2024-02-20T01:53:13.782873Z",
     "iopub.status.idle": "2024-02-20T01:53:13.832147Z",
     "shell.execute_reply": "2024-02-20T01:53:13.830983Z"
    },
    "papermill": {
     "duration": 0.069055,
     "end_time": "2024-02-20T01:53:13.834930",
     "exception": false,
     "start_time": "2024-02-20T01:53:13.765875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Transported</th>\n",
       "      <th>cabin_code</th>\n",
       "      <th>id_cabin</th>\n",
       "      <th>cabin_sector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>True</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>False</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>False</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  HomePlanet CryoSleep  Cabin  Destination   Age    VIP  RoomService  \\\n",
       "0     Europa     False  B/0/P  TRAPPIST-1e  39.0  False          0.0   \n",
       "1      Earth     False  F/0/S  TRAPPIST-1e  24.0  False        109.0   \n",
       "2     Europa     False  A/0/S  TRAPPIST-1e  58.0   True         43.0   \n",
       "3     Europa     False  A/0/S  TRAPPIST-1e  33.0  False          0.0   \n",
       "\n",
       "   FoodCourt  ShoppingMall     Spa  VRDeck  Transported cabin_code id_cabin  \\\n",
       "0        0.0           0.0     0.0     0.0        False          B        0   \n",
       "1        9.0          25.0   549.0    44.0         True          F        0   \n",
       "2     3576.0           0.0  6715.0    49.0        False          A        0   \n",
       "3     1283.0         371.0  3329.0   193.0        False          A        0   \n",
       "\n",
       "  cabin_sector  \n",
       "0            P  \n",
       "1            S  \n",
       "2            S  \n",
       "3            S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Splitting\n",
    "\n",
    "df[[\"cabin_code\",\"id_cabin\",\"cabin_sector\"]] = df[\"Cabin\"].str.split(\"/\", n=2, expand=True)\n",
    "\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53837498",
   "metadata": {
    "papermill": {
     "duration": 0.015432,
     "end_time": "2024-02-20T01:53:13.866511",
     "exception": false,
     "start_time": "2024-02-20T01:53:13.851079",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "First of all, I noticed that “cabin_code” only has 8 different characters which means that the cabins are, somehow, divided into 8 sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd1bab9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:53:13.900660Z",
     "iopub.status.busy": "2024-02-20T01:53:13.899408Z",
     "iopub.status.idle": "2024-02-20T01:53:13.921756Z",
     "shell.execute_reply": "2024-02-20T01:53:13.920455Z"
    },
    "papermill": {
     "duration": 0.045264,
     "end_time": "2024-02-20T01:53:13.927304",
     "exception": false,
     "start_time": "2024-02-20T01:53:13.882040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cabin_code\n",
       "A    0.030139\n",
       "B    0.091712\n",
       "C    0.087944\n",
       "D    0.056275\n",
       "E    0.103132\n",
       "F    0.328938\n",
       "G    0.301271\n",
       "T    0.000589\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cabinss = df.cabin_code.value_counts(1).sort_index()\n",
    "cabinss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7a4dc2",
   "metadata": {
    "papermill": {
     "duration": 0.020415,
     "end_time": "2024-02-20T01:53:13.968584",
     "exception": false,
     "start_time": "2024-02-20T01:53:13.948169",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Also, I asked myself if passengers from a specific section had a higher chance of being transported or if this statement was not true. With the plot below we can conclude that passengers from the B and C sections have a greater chance of surviving and passengers from the E section have a lower chance of surviving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4326da4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:53:14.007304Z",
     "iopub.status.busy": "2024-02-20T01:53:14.006005Z",
     "iopub.status.idle": "2024-02-20T01:53:14.419536Z",
     "shell.execute_reply": "2024-02-20T01:53:14.418448Z"
    },
    "papermill": {
     "duration": 0.434095,
     "end_time": "2024-02-20T01:53:14.422166",
     "exception": false,
     "start_time": "2024-02-20T01:53:13.988071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x450 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 4.5))\n",
    "_= sns.countplot(data=df, x=\"cabin_code\", hue=\"Transported\", palette=\"coolwarm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e717d0af",
   "metadata": {
    "papermill": {
     "duration": 0.015858,
     "end_time": "2024-02-20T01:53:14.454294",
     "exception": false,
     "start_time": "2024-02-20T01:53:14.438436",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "I did the same thing with the “cabin_sector” column and also noticed that there was a difference between the sectors. Passengers from the P sector have a lower chance of being transported, while in the S sector, the opposite happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e212b561",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:53:14.488471Z",
     "iopub.status.busy": "2024-02-20T01:53:14.488046Z",
     "iopub.status.idle": "2024-02-20T01:53:14.711965Z",
     "shell.execute_reply": "2024-02-20T01:53:14.710737Z"
    },
    "papermill": {
     "duration": 0.243928,
     "end_time": "2024-02-20T01:53:14.714380",
     "exception": false,
     "start_time": "2024-02-20T01:53:14.470452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1sAAAGZCAYAAAB/gyuTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAzOklEQVR4nO3de1RVdf7/8dcBuV+9AEcSvISiNuI942teUkdQx8nJLItvyngrlfwqmWaT1yzKzGteqknR0rTLVys1E0kxES8xg3fJHAwnRRwNEE1AOL8/+nm+nTAvyOaAPB9r7bXY+/M5e78/Z9bqzMv92Z9tslgsFgEAAAAAypWDvQsAAAAAgLsRYQsAAAAADEDYAgAAAAADELYAAAAAwACELQAAAAAwAGELAAAAAAxA2AIAAAAAA9SwdwFVQUlJiU6fPi0vLy+ZTCZ7lwMAAADATiwWiy5evKjAwEA5ONz43hVh6xacPn1aQUFB9i4DAAAAQCVx6tQp1atX74Z9CFu3wMvLS9IvX6i3t7edqwEAAABgL3l5eQoKCrJmhBshbN2Ca1MHvb29CVsAAAAAbunxIhbIAAAAAAADELYAAAAAwACELQAAAAAwAM9sAQDspri4WEVFRfYu467n5OQkR0dHe5cBANUOYQsAUOEsFouysrKUk5Nj71KqDV9fX5nNZt4XCQAViLAFAKhw14KWv7+/3N3dCQAGslgsunz5srKzsyVJdevWtXNFAFB9ELYAABWquLjYGrRq165t73KqBTc3N0lSdna2/P39mVIIABWEBTIAABXq2jNa7u7udq6kern2ffOMHABUHMIWAMAumDpYsfi+AaDiEbYAAAAAwACELQAA7hINGjTQvHnz7F0GAOD/I2wBACoNk8l0w23atGn2LrHcEZAA4O7FaoQAgErjzJkz1r/Xrl2rKVOmKD093XrM09PT+rfFYlFxcbFq1KiaP2WFhYVydna2dxkAAANxZwsAUGmYzWbr5uPjI5PJZN0/duyYvLy89OWXX6pt27ZycXHRzp07deLECT388MMKCAiQp6en2rdvr61bt9qct0GDBnr11Vc1ZMgQeXl5KTg4WO+88461vbCwUDExMapbt65cXV1Vv359xcXFWdtNJpOWLFmiXr16yc3NTY0aNdInn3xic42DBw+qW7ducnNzU+3atTVixAjl5+db26Ojo9WvXz+98sorCgwMVGhoqLp27aoffvhB48aNs969u2bnzp3q1KmT3NzcFBQUpDFjxujSpUvW9uzsbPXt21dubm5q2LChVq1aVW7/OwAAykfV/OdAAEC19cILL2j27Nlq1KiRatasqVOnTql379565ZVX5OLiopUrV6pv375KT09XcHCw9XNvvvmmXn75Zb344ov65JNPNHLkSHXp0kWhoaFasGCBPv/8c3300UcKDg7WqVOndOrUKZvrTp48Wa+99prmz5+v999/XwMHDtTBgwfVrFkzXbp0SREREQoPD9e+ffuUnZ2tYcOGKSYmRvHx8dZzJCYmytvbWwkJCZJ+ecFwy5YtNWLECA0fPtza78SJE4qMjNTMmTO1bNkynTt3TjExMYqJidHy5csl/RLeTp8+rW3btsnJyUljxoyxvrgYMNr5xDX2LgHVRO3uA+1dwh0hbAEAqpQZM2boj3/8o3W/Vq1aatmypXX/5Zdf1rp16/T5558rJibGerx3794aNWqUJGnixImaO3eutm3bptDQUGVmZqpx48Z68MEHZTKZVL9+/VLXHTBggIYNG2a9RkJCghYuXKjFixdr9erVunLlilauXCkPDw9J0ltvvaW+ffvq9ddfV0BAgCTJw8NDf//7322mDzo6OsrLy0tms9l6LC4uTlFRURo7dqwkqXHjxlqwYIG6dOmiJUuWKDMzU19++aX27t2r9u3bS5Lee+89NWvW7I6+WwBA+WIaIQCgSmnXrp3Nfn5+vsaPH69mzZrJ19dXnp6eOnr0qDIzM236hYWFWf++Nj3x2p2g6OhopaWlKTQ0VGPGjNGWLVtKXTc8PLzU/tGjRyVJR48eVcuWLa1BS5I6duyokpISm2fOWrRocUvPae3fv1/x8fHy9PS0bhERESopKVFGRoaOHj2qGjVqqG3bttbPNG3aVL6+vjc9NwCg4nBnCwBQpfw60EjS+PHjlZCQoNmzZyskJERubm569NFHVVhYaNPPycnJZt9kMqmkpESS1KZNG2VkZOjLL7/U1q1b9dhjj6lHjx6lnssq79p/T35+vp5++mmNGTOmVFtwcLC+++67cq0LAGAMwhYAoEpLTk5WdHS0/vKXv0j6JaicPHnyts/j7e2txx9/XI8//rgeffRRRUZG6sKFC6pVq5Ykaffu3Ro0aJC1/+7du9W6dWtJUrNmzRQfH69Lly5ZA1VycrIcHBwUGhp6w+s6OzuruLjY5libNm105MgRhYSEXPczTZs21dWrV5WammqdRpienq6cnJzbHjcAwDhMIwQAVGmNGzfW//7v/yotLU379+/Xk08+ab1jdavmzJmjDz/8UMeOHdN3332njz/+WGaz2WZa3scff6xly5bpu+++09SpU7V3717rM2FRUVFydXXV4MGDdejQIW3btk3PPvusnnrqKevzWr+nQYMG2rFjh3788Uf95z//kfTLM2W7du1STEyM0tLSdPz4cX322WfW64WGhioyMlJPP/209uzZo9TUVA0bNkxubm63NW4AgLEIWwCAKm3OnDmqWbOm/uu//kt9+/ZVRESE2rRpc1vn8PLy0qxZs9SuXTu1b99eJ0+e1KZNm+Tg8H8/k9OnT9eaNWsUFhamlStX6sMPP1Tz5s0lSe7u7vrqq6904cIFtW/fXo8++qi6d++ut95666bXnjFjhk6ePKl7771Xfn5+kn55viwpKUnfffedOnXqpNatW2vKlCkKDAy0fm758uUKDAxUly5d9Mgjj2jEiBHy9/e/rXEDAIxlslgsFnsXUdnl5eXJx8dHubm58vb2tnc5AFClXblyRRkZGWrYsKFcXV3tXc4tMZlMWrdunfr162fvUsqsKn7vqLxY+h0VpTIu/X472YA7WwAAAABgAMIWAAAAABiA1QjvApv25du7BFQTvdt72rsEwC6YcQ8AKAvubAEAAACAAQhbAAAAAGAAwhYAAAAAGICwBQAAAAAGIGwBAAAAgAEIWwAAAABgAMIWAAAVLD4+Xr6+vvYuAwBgMN6zBQCotCr6PYK3+y656OhorVixotTx48ePKyQkpLzKAgBUUYQtAADuQGRkpJYvX25zzM/Pz07VAAAqE6YRAgBwB1xcXGQ2m222+fPnq0WLFvLw8FBQUJBGjRql/Pzfv0u3f/9+PfTQQ/Ly8pK3t7fatm2rb7/91tq+c+dOderUSW5ubgoKCtKYMWN06dKlihgeAOAOELYAAChnDg4OWrBggQ4fPqwVK1bo66+/1oQJE363f1RUlOrVq6d9+/YpNTVVL7zwgpycnCRJJ06cUGRkpPr3768DBw5o7dq12rlzp2JiYipqOACAMmIaIQAAd2DDhg3y9Py/Z7169eqljz/+2LrfoEEDzZw5U88884wWL1583XNkZmbq+eefV9OmTSVJjRs3trbFxcUpKipKY8eOtbYtWLBAXbp00ZIlS+Tq6mrAqAAA5YGwBQDAHXjooYe0ZMkS676Hh4e2bt2quLg4HTt2THl5ebp69aquXLmiy5cvy93dvdQ5YmNjNWzYML3//vvq0aOHBgwYoHvvvVfSL1MMDxw4oFWrVln7WywWlZSUKCMjQ82aNTN+kACAMmEaIQAAd8DDw0MhISHWraCgQH/6058UFhamTz/9VKmpqVq0aJEkqbCw8LrnmDZtmg4fPqw+ffro66+/VvPmzbVu3TpJUn5+vp5++mmlpaVZt/379+v48ePWQAYAqJy4swUAQDlKTU1VSUmJ3nzzTTk4/PJvmh999NFNP9ekSRM1adJE48aN0xNPPKHly5frL3/5i9q0aaMjR46wlDwAVEHc2QIAoByFhISoqKhICxcu1L/+9S+9//77Wrp06e/2//nnnxUTE6Pt27frhx9+UHJysvbt22edHjhx4kTt2rVLMTExSktL0/Hjx/XZZ5+xQAYAVAGELQAAylHLli01Z84cvf766/rDH/6gVatWKS4u7nf7Ozo66vz58xo0aJCaNGmixx57TL169dL06dMlSWFhYUpKStJ3332nTp06qXXr1poyZYoCAwMrakgAgDIyWSwWi72LqOzy8vLk4+Oj3NxceXt727ucUjbt+/13twDlqXd7z5t3Am7iypUrysjIUMOGDVlJrwLxvaM8nU9cY+8SUE3U7j7Q3iWUcjvZgDtbAAAAAGAAwhYAAAAAGICwBQAAAAAGIGwBAAAAgAEIWwAAAABgAMIWAAAAABiAsAUAAAAABiBsAQAAAIABCFsAAAAAYADCFgAAAAAYoIa9CwAA4PecT1xToder3X3gLfc1mUw3bJ86daqmTZt2hxUBAKoywhYAAGVw5swZ699r167VlClTlJ6ebj3m6elp/dtisai4uFg1avCzCwDVCdMIAQAoA7PZbN18fHxkMpms+8eOHZOXl5e+/PJLtW3bVi4uLtq5c6eio6PVr18/m/OMHTtWXbt2te6XlJQoLi5ODRs2lJubm1q2bKlPPvmkYgcHACgX/BMbAAAGeeGFFzR79mw1atRINWvWvKXPxMXF6YMPPtDSpUvVuHFj7dixQ//93/8tPz8/denSxeCKAQDlibAFAIBBZsyYoT/+8Y+33L+goECvvvqqtm7dqvDwcElSo0aNtHPnTr399tuELQCoYghbAAAYpF27drfV//vvv9fly5dLBbTCwkK1bt26PEsDAFQAwhYAAAbx8PCw2XdwcJDFYrE5VlRUZP07Pz9fkrRx40bdc889Nv1cXFwMqhIAYBTCFgAAFcTPz0+HDh2yOZaWliYnJydJUvPmzeXi4qLMzEymDALAXYCwBQBABenWrZveeOMNrVy5UuHh4frggw906NAh6xRBLy8vjR8/XuPGjVNJSYkefPBB5ebmKjk5Wd7e3ho8eLCdRwAAuB2ELQBApXU7LxmuCiIiIjR58mRNmDBBV65c0ZAhQzRo0CAdPHjQ2ufll1+Wn5+f4uLi9K9//Uu+vr5q06aNXnzxRTtWDgAoC7u+ZysuLk7t27eXl5eX/P391a9fP5sXQkrSlStXNHr0aNWuXVuenp7q37+/zp49a9MnMzNTffr0kbu7u/z9/fX888/r6tWrNn22b9+uNm3ayMXFRSEhIYqPjzd6eACAaiI6Olo5OTnW/a5du8piscjX17dU3+nTpysrK0s5OTmaM2eOFi5cqO3bt1vbTSaT/ud//kfHjh1TYWGhsrOztXnzZnXu3Nn4gQAAypVdw1ZSUpJGjx6t3bt3KyEhQUVFRerZs6cuXbpk7TNu3Dh98cUX+vjjj5WUlKTTp0/rkUcesbYXFxerT58+Kiws1K5du7RixQrFx8drypQp1j4ZGRnq06ePHnroIaWlpWns2LEaNmyYvvrqqwodLwAAAIDqw2T57bJIdnTu3Dn5+/srKSlJnTt3Vm5urvz8/LR69Wo9+uijkqRjx46pWbNmSklJ0QMPPKAvv/xSf/rTn3T69GkFBARIkpYuXaqJEyfq3LlzcnZ21sSJE7Vx40abh5IHDhyonJwcbd68uVQdBQUFKigosO7n5eUpKChIubm58vb2NvhbuH2b9uXbuwRUE73be9q7BNwFrly5ooyMDDVs2FCurq72Lqfa4HtHeTqfuMbeJaCaqIzTyfPy8uTj43NL2cCud7Z+Kzc3V5JUq1YtSVJqaqqKiorUo0cPa5+mTZsqODhYKSkpkqSUlBS1aNHCGrSkX+bE5+Xl6fDhw9Y+vz7HtT7XzvFbcXFx8vHxsW5BQUHlN0gAAAAA1UKlCVslJSUaO3asOnbsqD/84Q+SpKysLDk7O5ea8x4QEKCsrCxrn18HrWvt19pu1CcvL08///xzqVomTZqk3Nxc63bq1KlyGSMAAACA6qPSrEY4evRoHTp0SDt37rR3KXJxceHlkQBgsEo0i71a4PsGgIpXKe5sxcTEaMOGDdq2bZvq1atnPW42m1VYWGizwpMknT17Vmaz2drnt6sTXtu/WR9vb2+5ubmV93AAADdw7QW+ly9ftnMl1cu17/va9w8AMJ5d72xZLBY9++yzWrdunbZv366GDRvatLdt21ZOTk5KTExU//79JUnp6enKzMxUeHi4JCk8PFyvvPKKsrOz5e/vL0lKSEiQt7e3mjdvbu2zadMmm3MnJCRYzwEAqDiOjo7y9fVVdna2JMnd3V0mk8nOVd29LBaLLl++rOzsbPn6+srR0dHeJQFAtWHXsDV69GitXr1an332mby8vKzPWPn4+MjNzU0+Pj4aOnSoYmNjVatWLXl7e+vZZ59VeHi4HnjgAUlSz5491bx5cz311FOaNWuWsrKy9NJLL2n06NHWqYDPPPOM3nrrLU2YMEFDhgzR119/rY8++kgbN26029gBoDq7NvPgWuCC8Xx9fa3fOwCgYtg1bC1ZskTSLy9//LXly5crOjpakjR37lw5ODiof//+KigoUEREhBYvXmzt6+joqA0bNmjkyJEKDw+Xh4eHBg8erBkzZlj7NGzYUBs3btS4ceM0f/581atXT3//+98VERFh+BgBAKWZTCbVrVtX/v7+Kioqsnc5dz0nJyfuaAGAHVSq92xVVrezlr498J4tVBTeswUAkHjPFioO79kCAAAAAJRC2AIAAAAAAxC2AAAAAMAAhC0AAAAAMABhCwAAAAAMYNel3wEAQPlhdVpUlA72LgCoIghbAG4ZS/2iolTGpX4BALhdTCMEAAAAAAMQtgAAAADAAIQtAAAAADAAYQsAAAAADEDYAgAAAAADELYAAAAAwACELQAAAAAwAGELAAAAAAxA2AIAAAAAAxC2AAAAAMAAhC0AAAAAMABhCwAAAAAMQNgCAAAAAAMQtgAAAADAAIQtAAAAADAAYQsAAAAADEDYAgAAAAADELYAAAAAwACELQAAAAAwAGELAAAAAAxA2AIAAAAAAxC2AAAAAMAAhC0AAAAAMABhCwAAAAAMQNgCAAAAAAMQtgAAAADAAIQtAAAAADAAYQsAAAAADEDYAgAAAAADELYAAAAAwACELQAAAAAwAGELAAAAAAxA2AIAAAAAAxC2AAAAAMAAhC0AAAAAMABhCwAAAAAMQNgCAAAAAAMQtgAAAADAAIQtAAAAADAAYQsAAAAADEDYAgAAAAADELYAAAAAwACELQAAAAAwAGELAAAAAAxA2AIAAAAAAxC2AAAAAMAAhC0AAAAAMABhCwAAAAAMQNgCAAAAAAMQtgAAAADAAIQtAAAAADCAXcPWjh071LdvXwUGBspkMmn9+vU27dHR0TKZTDZbZGSkTZ8LFy4oKipK3t7e8vX11dChQ5Wfn2/T58CBA+rUqZNcXV0VFBSkWbNmGT00AAAAANWcXcPWpUuX1LJlSy1atOh3+0RGRurMmTPW7cMPP7Rpj4qK0uHDh5WQkKANGzZox44dGjFihLU9Ly9PPXv2VP369ZWamqo33nhD06ZN0zvvvGPYuAAAAACghj0v3qtXL/Xq1euGfVxcXGQ2m6/bdvToUW3evFn79u1Tu3btJEkLFy5U7969NXv2bAUGBmrVqlUqLCzUsmXL5OzsrPvuu09paWmaM2eOTSgDAAAAgPJU6Z/Z2r59u/z9/RUaGqqRI0fq/Pnz1raUlBT5+vpag5Yk9ejRQw4ODtqzZ4+1T+fOneXs7GztExERofT0dP3000/XvWZBQYHy8vJsNgAAAAC4HZU6bEVGRmrlypVKTEzU66+/rqSkJPXq1UvFxcWSpKysLPn7+9t8pkaNGqpVq5aysrKsfQICAmz6XNu/1ue34uLi5OPjY92CgoLKe2gAAAAA7nJ2nUZ4MwMHDrT+3aJFC4WFhenee+/V9u3b1b17d8OuO2nSJMXGxlr38/LyCFwAAAAAbkulvrP1W40aNVKdOnX0/fffS5LMZrOys7Nt+ly9elUXLlywPudlNpt19uxZmz7X9n/vWTAXFxd5e3vbbAAAAABwO6pU2Pr3v/+t8+fPq27dupKk8PBw5eTkKDU11drn66+/VklJiTp06GDts2PHDhUVFVn7JCQkKDQ0VDVr1qzYAQAAAACoNuwatvLz85WWlqa0tDRJUkZGhtLS0pSZman8/Hw9//zz2r17t06ePKnExEQ9/PDDCgkJUUREhCSpWbNmioyM1PDhw7V3714lJycrJiZGAwcOVGBgoCTpySeflLOzs4YOHarDhw9r7dq1mj9/vs00QQAAAAAob3YNW99++61at26t1q1bS5JiY2PVunVrTZkyRY6Ojjpw4ID+/Oc/q0mTJho6dKjatm2rb775Ri4uLtZzrFq1Sk2bNlX37t3Vu3dvPfjggzbv0PLx8dGWLVuUkZGhtm3b6rnnntOUKVNY9h0AAACAoey6QEbXrl1lsVh+t/2rr7666Tlq1aql1atX37BPWFiYvvnmm9uuDwAAAADKqko9swUAAAAAVQVhCwAAAAAMQNgCAAAAAAMQtgAAAADAAIQtAAAAADAAYQsAAAAADEDYAgAAAAADELYAAAAAwACELQAAAAAwAGELAAAAAAxA2AIAAAAAA5QpbHXr1k05OTmljufl5albt253WhMAAAAAVHllClvbt29XYWFhqeNXrlzRN998c8dFAQAAAEBVV+N2Oh84cMD695EjR5SVlWXdLy4u1ubNm3XPPfeUX3UAAAAAUEXdVthq1aqVTCaTTCbTdacLurm5aeHCheVWHAAAAABUVbcVtjIyMmSxWNSoUSPt3btXfn5+1jZnZ2f5+/vL0dGx3IsEAAAAgKrmtsJW/fr1JUklJSWGFAMAAAAAd4vbClu/dvz4cW3btk3Z2dmlwteUKVPuuDAAAAAAqMrKFLbeffddjRw5UnXq1JHZbJbJZLK2mUwmwhYAAACAaq9MYWvmzJl65ZVXNHHixPKuBwAAAADuCmV6z9ZPP/2kAQMGlHctAAAAAHDXKFPYGjBggLZs2VLetQAAAADAXaNM0whDQkI0efJk7d69Wy1atJCTk5NN+5gxY8qlOAAAAACoqsoUtt555x15enoqKSlJSUlJNm0mk4mwBQAAAKDaK1PYysjIKO86AAAAAOCuUqZntgAAAAAAN1amO1tDhgy5YfuyZcvKVAwAAAAA3C3KFLZ++uknm/2ioiIdOnRIOTk56tatW7kUBgAAAABVWZnC1rp160odKykp0ciRI3XvvffecVEAAAAAUNWV2zNbDg4Oio2N1dy5c8vrlAAAAABQZZXrAhknTpzQ1atXy/OUAAAAAFAllWkaYWxsrM2+xWLRmTNntHHjRg0ePLhcCgMAAACAqqxMYeuf//ynzb6Dg4P8/Pz05ptv3nSlQgAAAACoDsoUtrZt21bedQAAAADAXaVMYeuac+fOKT09XZIUGhoqPz+/cikKAAAAAKq6Mi2QcenSJQ0ZMkR169ZV586d1blzZwUGBmro0KG6fPlyedcIAAAAAFVOmcJWbGyskpKS9MUXXygnJ0c5OTn67LPPlJSUpOeee668awQAAACAKqdM0wg//fRTffLJJ+ratav1WO/eveXm5qbHHntMS5YsKa/6AAAAAKBKKtOdrcuXLysgIKDUcX9/f6YRAgAAAIDKGLbCw8M1depUXblyxXrs559/1vTp0xUeHl5uxQEAAABAVVWmaYTz5s1TZGSk6tWrp5YtW0qS9u/fLxcXF23ZsqVcCwQAAACAqqhMYatFixY6fvy4Vq1apWPHjkmSnnjiCUVFRcnNza1cCwQAAACAqqhMYSsuLk4BAQEaPny4zfFly5bp3LlzmjhxYrkUBwAAAABVVZme2Xr77bfVtGnTUsfvu+8+LV269I6LAgAAAICqrkxhKysrS3Xr1i113M/PT2fOnLnjogAAAACgqitT2AoKClJycnKp48nJyQoMDLzjogAAAACgqivTM1vDhw/X2LFjVVRUpG7dukmSEhMTNWHCBD333HPlWiAAAAAAVEVlClvPP/+8zp8/r1GjRqmwsFCS5OrqqokTJ2rSpEnlWiAAAAAAVEVlClsmk0mvv/66Jk+erKNHj8rNzU2NGzeWi4tLedcHAAAAAFVSmcLWNZ6enmrfvn151QIAAAAAd40yLZABAAAAALgxwhYAAAAAGICwBQAAAAAGIGwBAAAAgAEIWwAAAABgAMIWAAAAABiAsAUAAAAABiBsAQAAAIAB7Bq2duzYob59+yowMFAmk0nr16+3abdYLJoyZYrq1q0rNzc39ejRQ8ePH7fpc+HCBUVFRcnb21u+vr4aOnSo8vPzbfocOHBAnTp1kqurq4KCgjRr1iyjhwYAAACgmrNr2Lp06ZJatmypRYsWXbd91qxZWrBggZYuXao9e/bIw8NDERERunLlirVPVFSUDh8+rISEBG3YsEE7duzQiBEjrO15eXnq2bOn6tevr9TUVL3xxhuaNm2a3nnnHcPHBwAAAKD6qmHPi/fq1Uu9evW6bpvFYtG8efP00ksv6eGHH5YkrVy5UgEBAVq/fr0GDhyoo0ePavPmzdq3b5/atWsnSVq4cKF69+6t2bNnKzAwUKtWrVJhYaGWLVsmZ2dn3XfffUpLS9OcOXNsQhkAAAAAlKdK+8xWRkaGsrKy1KNHD+sxHx8fdejQQSkpKZKklJQU+fr6WoOWJPXo0UMODg7as2ePtU/nzp3l7Oxs7RMREaH09HT99NNP1712QUGB8vLybDYAAAAAuB2VNmxlZWVJkgICAmyOBwQEWNuysrLk7+9v016jRg3VqlXLps/1zvHra/xWXFycfHx8rFtQUNCdDwgAAABAtVJpw5Y9TZo0Sbm5udbt1KlT9i4JAAAAQBVTacOW2WyWJJ09e9bm+NmzZ61tZrNZ2dnZNu1Xr17VhQsXbPpc7xy/vsZvubi4yNvb22YDAAAAgNtRacNWw4YNZTablZiYaD2Wl5enPXv2KDw8XJIUHh6unJwcpaamWvt8/fXXKikpUYcOHax9duzYoaKiImufhIQEhYaGqmbNmhU0GgAAAADVjV3DVn5+vtLS0pSWlibpl0Ux0tLSlJmZKZPJpLFjx2rmzJn6/PPPdfDgQQ0aNEiBgYHq16+fJKlZs2aKjIzU8OHDtXfvXiUnJysmJkYDBw5UYGCgJOnJJ5+Us7Ozhg4dqsOHD2vt2rWaP3++YmNj7TRqAAAAANWBXZd+//bbb/XQQw9Z968FoMGDBys+Pl4TJkzQpUuXNGLECOXk5OjBBx/U5s2b5erqav3MqlWrFBMTo+7du8vBwUH9+/fXggULrO0+Pj7asmWLRo8erbZt26pOnTqaMmUKy74DAAAAMJTJYrFY7F1EZZeXlycfHx/l5uZWyue3Nu3Lt3cJqCY65G2wdwmoJmp3H2jvEqokfg9QUfg9QEWpjL8Ht5MNKu0zWwAAAABQlRG2AAAAAMAAhC0AAAAAMABhCwAAAAAMQNgCAAAAAAMQtgAAAADAAIQtAAAAADAAYQsAAAAADEDYAgAAAAADELYAAAAAwACELQAAAAAwAGELAAAAAAxA2AIAAAAAAxC2AAAAAMAAhC0AAAAAMABhCwAAAAAMQNgCAAAAAAMQtgAAAADAAIQtAAAAADAAYQsAAAAADEDYAgAAAAADELYAAAAAwACELQAAAAAwAGELAAAAAAxA2AIAAAAAAxC2AAAAAMAAhC0AAAAAMABhCwAAAAAMQNgCAAAAAAMQtgAAAADAAIQtAAAAADAAYQsAAAAADEDYAgAAAAADELYAAAAAwACELQAAAAAwAGELAAAAAAxA2AIAAAAAAxC2AAAAAMAAhC0AAAAAMABhCwAAAAAMQNgCAAAAAAMQtgAAAADAAIQtAAAAADAAYQsAAAAADEDYAgAAAAADELYAAAAAwACELQAAAAAwAGELAAAAAAxA2AIAAAAAAxC2AAAAAMAAhC0AAAAAMABhCwAAAAAMQNgCAAAAAAMQtgAAAADAAIQtAAAAADAAYQsAAAAADEDYAgAAAAADELYAAAAAwACELQAAAAAwQKUOW9OmTZPJZLLZmjZtam2/cuWKRo8erdq1a8vT01P9+/fX2bNnbc6RmZmpPn36yN3dXf7+/nr++ed19erVih4KAAAAgGqmhr0LuJn77rtPW7dute7XqPF/JY8bN04bN27Uxx9/LB8fH8XExOiRRx5RcnKyJKm4uFh9+vSR2WzWrl27dObMGQ0aNEhOTk569dVXK3wsAAAAAKqPSh+2atSoIbPZXOp4bm6u3nvvPa1evVrdunWTJC1fvlzNmjXT7t279cADD2jLli06cuSItm7dqoCAALVq1Uovv/yyJk6cqGnTpsnZ2fm61ywoKFBBQYF1Py8vz5jBAQAAALhrVepphJJ0/PhxBQYGqlGjRoqKilJmZqYkKTU1VUVFRerRo4e1b9OmTRUcHKyUlBRJUkpKilq0aKGAgABrn4iICOXl5enw4cO/e824uDj5+PhYt6CgIINGBwAAAOBuVanDVocOHRQfH6/NmzdryZIlysjIUKdOnXTx4kVlZWXJ2dlZvr6+Np8JCAhQVlaWJCkrK8smaF1rv9b2eyZNmqTc3FzrdurUqfIdGAAAAIC7XqWeRtirVy/r32FhYerQoYPq16+vjz76SG5uboZd18XFRS4uLoadHwAAAMDdr1Lf2fotX19fNWnSRN9//73MZrMKCwuVk5Nj0+fs2bPWZ7zMZnOp1Qmv7V/vOTAAAAAAKC9VKmzl5+frxIkTqlu3rtq2bSsnJyclJiZa29PT05WZmanw8HBJUnh4uA4ePKjs7Gxrn4SEBHl7e6t58+YVXj8AAACA6qNSTyMcP368+vbtq/r16+v06dOaOnWqHB0d9cQTT8jHx0dDhw5VbGysatWqJW9vbz377LMKDw/XAw88IEnq2bOnmjdvrqeeekqzZs1SVlaWXnrpJY0ePZppggAAAAAMVanD1r///W898cQTOn/+vPz8/PTggw9q9+7d8vPzkyTNnTtXDg4O6t+/vwoKChQREaHFixdbP+/o6KgNGzZo5MiRCg8Pl4eHhwYPHqwZM2bYa0gAAAAAqolKHbbWrFlzw3ZXV1ctWrRIixYt+t0+9evX16ZNm8q7NAAAAAC4oSr1zBYAAAAAVBWELQAAAAAwAGELAAAAAAxA2AIAAAAAAxC2AAAAAMAAhC0AAAAAMABhCwAAAAAMQNgCAAAAAAMQtgAAAADAAIQtAAAAADAAYQsAAAAADEDYAgAAAAADELYAAAAAwACELQAAAAAwAGELAAAAAAxA2AIAAAAAAxC2AAAAAMAAhC0AAAAAMABhCwAAAAAMQNgCAAAAAAMQtgAAAADAAIQtAAAAADAAYQsAAAAADEDYAgAAAAADELYAAAAAwACELQAAAAAwAGELAAAAAAxA2AIAAAAAAxC2AAAAAMAAhC0AAAAAMABhCwAAAAAMQNgCAAAAAAMQtgAAAADAAIQtAAAAADAAYQsAAAAADEDYAgAAAAADELYAAAAAwACELQAAAAAwAGELAAAAAAxA2AIAAAAAAxC2AAAAAMAAhC0AAAAAMABhCwAAAAAMQNgCAAAAAAMQtgAAAADAAIQtAAAAADAAYQsAAAAADEDYAgAAAAADELYAAAAAwACELQAAAAAwAGELAAAAAAxA2AIAAAAAAxC2AAAAAMAAhC0AAAAAMABhCwAAAAAMQNgCAAAAAAMQtgAAAADAAIQtAAAAADBAtQpbixYtUoMGDeTq6qoOHTpo79699i4JAAAAwF2q2oSttWvXKjY2VlOnTtU//vEPtWzZUhEREcrOzrZ3aQAAAADuQtUmbM2ZM0fDhw/XX//6VzVv3lxLly6Vu7u7li1bZu/SAAAAANyFati7gIpQWFio1NRUTZo0yXrMwcFBPXr0UEpKSqn+BQUFKigosO7n5uZKkvLy8owvtgwu5+fbuwRUExcvXbZ3CagmnCrpf28rO34PUFH4PUBFqYy/B9cygcViuWnfahG2/vOf/6i4uFgBAQE2xwMCAnTs2LFS/ePi4jR9+vRSx4OCggyrEQDwa0PtXQAAoFKovL8HFy9elI+Pzw37VIuwdbsmTZqk2NhY635JSYkuXLig2rVry2Qy2bEywH7y8vIUFBSkU6dOydvb297lAADshN8DVHcWi0UXL15UYGDgTftWi7BVp04dOTo66uzZszbHz549K7PZXKq/i4uLXFxcbI75+voaWSJQZXh7e/PjCgDg9wDV2s3uaF1TLRbIcHZ2Vtu2bZWYmGg9VlJSosTERIWHh9uxMgAAAAB3q2pxZ0uSYmNjNXjwYLVr107333+/5s2bp0uXLumvf/2rvUsDAAAAcBeqNmHr8ccf17lz5zRlyhRlZWWpVatW2rx5c6lFMwBcn4uLi6ZOnVpqii0AoHrh9wC4dSbLraxZCAAAAAC4LdXimS0AAAAAqGiELQAAAAAwAGELAAAAAAxA2AIAAAAAAxC2ANxQdHS0TCaTTCaTnJ2dFRISohkzZujq1av2Lg0AUIHOnTunkSNHKjg4WC4uLjKbzYqIiFBycrK9SwMqrWqz9DuAsouMjNTy5ctVUFCgTZs2afTo0XJyctKkSZPsXRoAoIL0799fhYWFWrFihRo1aqSzZ88qMTFR58+ft3dpQKXF0u8Abig6Olo5OTlav3699VjPnj118eJFpaSk2K8wAECFycnJUc2aNbV9+3Z16dLF3uUAVQbTCAHcNjc3NxUWFtq7DABABfH09JSnp6fWr1+vgoICe5cDVBmELQC3zGKxaOvWrfrqq6/UrVs3e5cDAKggNWrUUHx8vFasWCFfX1917NhRL774og4cOGDv0oBKjbAF4KY2bNggT09Pubq6qlevXnr88cc1bdo0e5cFAKhA/fv31+nTp/X5558rMjJS27dvV5s2bRQfH2/v0oBKi2e2ANxQdHS0fvzxRy1ZskTOzs4KDAxUjRqsrQMAkIYNG6aEhAT98MMP9i4FqJS4swXgpjw8PBQSEqLg4GCCFgDAqnnz5rp06ZK9ywAqLf5fEwAAAG7o/PnzGjBggIYMGaKwsDB5eXnp22+/1axZs/Twww/buzyg0iJsAQAA4IY8PT3VoUMHzZ07VydOnFBRUZGCgoI0fPhwvfjii/YuD6i0eGYLAAAAAAzAM1sAAAAAYADCFgAAAAAYgLAFAAAAAAYgbAEAAACAAQhbAAAAAGAAwhYAAAAAGICwBQAAAAAGIGwBAAAAgAEIWwCAKm/atGlq1arVDftER0erX79+FVIPAACSVMPeBQAAUBHmz58vi8Vi7zJuSdeuXdWqVSvNmzfP3qUAAO4AYQsAUC34+PjYu4QKV1hYKGdnZ3uXAQDVFtMIAQCVQklJiWbNmqWQkBC5uLgoODhYr7zyiiRp4sSJatKkidzd3dWoUSNNnjxZRUVFpc7x9ttvKygoSO7u7nrssceUm5trbfvtNMKuXbtqzJgxmjBhgmrVqiWz2axp06bdUq0Wi0XTpk1TcHCwXFxcFBgYqDFjxljbCwoKNH78eN1zzz3y8PBQhw4dtH37dptzJCcnq2vXrnJ3d1fNmjUVERGhn376SdHR0UpKStL8+fNlMplkMpl08uRJSVJSUpLuv/9+ubi4qG7dunrhhRd09epVmzHFxMRo7NixqlOnjiIiIm5pPAAAYxC2AACVwqRJk/Taa69p8uTJOnLkiFavXq2AgABJkpeXl+Lj43XkyBHNnz9f7777rubOnWvz+e+//14fffSRvvjiC23evFn//Oc/NWrUqBtec8WKFfLw8NCePXs0a9YszZgxQwkJCTet9dNPP9XcuXP19ttv6/jx41q/fr1atGhhbY+JiVFKSorWrFmjAwcOaMCAAYqMjNTx48clSWlpaerevbuaN2+ulJQU7dy5U3379lVxcbHmz5+v8PBwDR8+XGfOnNGZM2cUFBSkH3/8Ub1791b79u21f/9+LVmyRO+9955mzpxZakzOzs5KTk7W0qVLb+m7BwAYw2SpKhPYAQB3rYsXL8rPz09vvfWWhg0bdtP+s2fP1po1a/Ttt99K+mWBjJkzZ+qHH37QPffcI0navHmz+vTpox9//FFms1nR0dHKycnR+vXrJf1yF6i4uFjffPON9bz333+/unXrptdee+2G158zZ47efvttHTp0SE5OTjZtmZmZatSokTIzMxUYGGg93qNHD91///169dVX9eSTTyozM1M7d+687vmv98zW3/72N3366ac6evSoTCaTJGnx4sWaOHGicnNz5eDgoK5duyovL0//+Mc/bvodAgCMx50tAIDdHT16VAUFBerevft129euXauOHTvKbDbL09NTL730kjIzM236BAcHW4OWJIWHh6ukpETp6em/e92wsDCb/bp16yo7O/um9Q4YMEA///yzGjVqpOHDh2vdunXW6XwHDx5UcXGxmjRpIk9PT+uWlJSkEydOSPq/O1u34+jRowoPD7cGLUnq2LGj8vPz9e9//9t6rG3btrd1XgCAcVggAwBgd25ubr/blpKSoqioKE2fPl0RERHy8fHRmjVr9Oabb97xdX97V8pkMqmkpOSmnwsKClJ6erq2bt2qhIQEjRo1Sm+88YaSkpKUn58vR0dHpaamytHR0eZznp6ekm483jvl4eFh2LkBALeHO1sAALtr3Lix3NzclJiYWKpt165dql+/vv72t7+pXbt2aty4sX744YdS/TIzM3X69Gnr/u7du+Xg4KDQ0FBDanZzc1Pfvn21YMECbd++XSkpKTp48KBat26t4uJiZWdnKyQkxGYzm82Sfrmjdr2xXuPs7Kzi4mKbY82aNVNKSorN8vXJycny8vJSvXr1DBkjAODOcGcLAGB3rq6umjhxoiZMmCBnZ2d17NhR586d0+HDh9W4cWNlZmZqzZo1at++vTZu3Kh169Zd9xyDBw/W7NmzlZeXpzFjxuixxx6zBpzyFB8fr+LiYnXo0EHu7u764IMP5Obmpvr166t27dqKiorSoEGD9Oabb6p169Y6d+6cEhMTFRYWpj59+mjSpElq0aKFRo0apWeeeUbOzs7atm2bBgwYoDp16qhBgwbas2ePTp48KU9PT9WqVUujRo3SvHnz9OyzzyomJkbp6emaOnWqYmNj5eDAv50CQGXEf50BAJXC5MmT9dxzz2nKlClq1qyZHn/8cWVnZ+vPf/6zxo0bp5iYGLVq1Uq7du3S5MmTS30+JCREjzzyiHr37q2ePXsqLCxMixcvNqRWX19fvfvuu+rYsaPCwsK0detWffHFF6pdu7Ykafny5Ro0aJCee+45hYaGql+/ftq3b5+Cg4MlSU2aNNGWLVu0f/9+3X///QoPD9dnn32mGjV++TfQ8ePHy9HRUc2bN5efn58yMzN1zz33aNOmTdq7d69atmypZ555RkOHDtVLL71kyBgBAHeO1QgBAAAAwADc2QIAAAAAAxC2AAD4jVWrVtks2/7r7b777rN3eQCAKoJphAAA/MbFixd19uzZ67Y5OTmpfv36FVwRAKAqImwBAAAAgAGYRggAAAAABiBsAQAAAIABCFsAAAAAYADCFgAAAAAYgLAFAAAAAAYgbAEAAACAAQhbAAAAAGCA/weByrxEs9eYVgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x450 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 4.5))\n",
    "_= sns.countplot(data=df, x=\"cabin_sector\", hue=\"Transported\", palette=\"coolwarm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aeeb4d3",
   "metadata": {
    "papermill": {
     "duration": 0.016506,
     "end_time": "2024-02-20T01:53:14.747529",
     "exception": false,
     "start_time": "2024-02-20T01:53:14.731023",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This means that this exploration of the original “Cabin” column is worth it since new insights are being added to the model.\n",
    "\n",
    "Now, we can finally delete the “Cabin” column. It will not provide any useful information for the model anymore. We have already extracted everything useful from it.\n",
    "\n",
    "I also removed the “cabin_id” and the column that I had created. As I said before, the Id will not interfere with the model’s predictive ability.\n",
    "\n",
    "So used: df.drop(columns=[“Cabin”,”id_cabin”], inplace=True) to drop both columns\n",
    "\n",
    "Before splitting our data, the “Transported” column must be in a binary format. As you can see, I switched “True” for 1 and “False” for 0.\n",
    "\n",
    "Binary transformation: df[“Transported”] = df[“Transported”].map({True:1, False:0})\n",
    "\n",
    "I also removed every row that had missing values in the “cabin_code” column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1395fa19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:53:14.784733Z",
     "iopub.status.busy": "2024-02-20T01:53:14.783663Z",
     "iopub.status.idle": "2024-02-20T01:53:14.794158Z",
     "shell.execute_reply": "2024-02-20T01:53:14.793168Z"
    },
    "papermill": {
     "duration": 0.031308,
     "end_time": "2024-02-20T01:53:14.796743",
     "exception": false,
     "start_time": "2024-02-20T01:53:14.765435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pop_id_cabin = df.pop(\"id_cabin\")\n",
    "df.insert(3, 'id_cabin', pop_id_cabin)  # Insert column 'C' at the beginning\n",
    "\n",
    "pop_id_cabin = df.pop(\"cabin_sector\")\n",
    "df.insert(3, 'cabin_sector', pop_id_cabin)  # Insert column 'C' at the beg\n",
    "\n",
    "pop_id_cabin = df.pop(\"cabin_code\")\n",
    "df.insert(3, 'cabin_code', pop_id_cabin)  # Insert column 'C' at the beg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6461a68d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:53:14.833643Z",
     "iopub.status.busy": "2024-02-20T01:53:14.833231Z",
     "iopub.status.idle": "2024-02-20T01:53:14.846924Z",
     "shell.execute_reply": "2024-02-20T01:53:14.845999Z"
    },
    "papermill": {
     "duration": 0.035562,
     "end_time": "2024-02-20T01:53:14.849339",
     "exception": false,
     "start_time": "2024-02-20T01:53:14.813777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#BINARY TRANSFORMATION\n",
    "df[\"Transported\"] = df[\"Transported\"].map({True:1, False:0})\n",
    "\n",
    "\n",
    "#DROPPING COLUMNS\n",
    "df.drop(columns=[\"Cabin\",\"id_cabin\"], inplace=True)\n",
    "\n",
    "\n",
    "#DROPPING NULLS\n",
    "df.dropna(subset=[\"cabin_code\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a34336",
   "metadata": {
    "papermill": {
     "duration": 0.016769,
     "end_time": "2024-02-20T01:53:14.883126",
     "exception": false,
     "start_time": "2024-02-20T01:53:14.866357",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, we can finally split the data and proceed to develop our model.\n",
    "\n",
    "After splitting in train and test, I separated the test data into two categories: numerical and categorical. Why is that? We are going to perform different operations depending on the type of the variable. Categorical data must be encoded since most models are not able to understand categorical values and it must be converted to numerical values. Also, we are going to apply different techniques to fill the null values in our dataset, but I will talk more about it later on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c834f26",
   "metadata": {
    "papermill": {
     "duration": 0.01673,
     "end_time": "2024-02-20T01:53:14.917086",
     "exception": false,
     "start_time": "2024-02-20T01:53:14.900356",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Splitting Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6839a09d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:53:14.953970Z",
     "iopub.status.busy": "2024-02-20T01:53:14.952980Z",
     "iopub.status.idle": "2024-02-20T01:53:14.960514Z",
     "shell.execute_reply": "2024-02-20T01:53:14.959198Z"
    },
    "papermill": {
     "duration": 0.028254,
     "end_time": "2024-02-20T01:53:14.962862",
     "exception": false,
     "start_time": "2024-02-20T01:53:14.934608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Define X and y\n",
    "\n",
    "X = df.iloc[:,0:12]\n",
    "y = df[\"Transported\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56af376",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:53:14.999994Z",
     "iopub.status.busy": "2024-02-20T01:53:14.999235Z",
     "iopub.status.idle": "2024-02-20T01:53:15.009883Z",
     "shell.execute_reply": "2024-02-20T01:53:15.008682Z"
    },
    "papermill": {
     "duration": 0.032411,
     "end_time": "2024-02-20T01:53:15.012507",
     "exception": false,
     "start_time": "2024-02-20T01:53:14.980096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Data splitting\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=42,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309cbe63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:53:15.049476Z",
     "iopub.status.busy": "2024-02-20T01:53:15.048781Z",
     "iopub.status.idle": "2024-02-20T01:53:15.055658Z",
     "shell.execute_reply": "2024-02-20T01:53:15.054804Z"
    },
    "papermill": {
     "duration": 0.028234,
     "end_time": "2024-02-20T01:53:15.058031",
     "exception": false,
     "start_time": "2024-02-20T01:53:15.029797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Separate categorical and numerical\n",
    "\n",
    "cat_feat = np.array([coluna for coluna in X_train.columns if X_train[coluna].dtype.name == 'object'])\n",
    "\n",
    "num_feat = np.array([coluna for coluna in X_train.columns if coluna not in cat_feat])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bb28ba",
   "metadata": {
    "papermill": {
     "duration": 0.017115,
     "end_time": "2024-02-20T01:53:15.092895",
     "exception": false,
     "start_time": "2024-02-20T01:53:15.075780",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can now create our pipeline. There are going to be two pipelines: one is going to handle the categorical data and the other one is going to handle numerical data. The missing values of the categorical data will be filled with the most frequent value (mode) and after the Target Encoder will be applied to transform categorical variables into numerical variables. The numerical data missing values will be filled with a strategy called K-nearest neighbors, which uses the Euclidean distance between the data points to find the best number to fill the missing values. If don’t know how this Pipeline technique works, I recommend you check my article about Pipelines. (\"https://medium.com/@fernandao.lacerda.dantas/boost-your-pipelines-with-columntransformer-b2c009db096f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a22ae0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:53:15.194557Z",
     "iopub.status.busy": "2024-02-20T01:53:15.193842Z",
     "iopub.status.idle": "2024-02-20T01:53:15.199839Z",
     "shell.execute_reply": "2024-02-20T01:53:15.198978Z"
    },
    "papermill": {
     "duration": 0.028442,
     "end_time": "2024-02-20T01:53:15.202235",
     "exception": false,
     "start_time": "2024-02-20T01:53:15.173793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Categorical and numerical pipelines\n",
    "\n",
    "\n",
    "cat_pipe = Pipeline([(\"imputer_cat\", SimpleImputer(strategy=\"most_frequent\")),(\"encoder\", ce.TargetEncoder()),\n",
    "                    ])\n",
    "\n",
    "num_pipe = Pipeline([(\"imputer_num\", KNNImputer(n_neighbors=3))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80385f4f",
   "metadata": {
    "papermill": {
     "duration": 0.017691,
     "end_time": "2024-02-20T01:53:15.237405",
     "exception": false,
     "start_time": "2024-02-20T01:53:15.219714",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "And with column transformer, we can attach both transformations to one variable that I named “transformer”. Observe that we also have to specify the type of data to which the pipeline will be applied to: “cat_pipe” will be applied to “cat_feat” and “num_pipe” will be applied to “num_feat”, meaning the categorical pipeline will take care of the categorical data and the numerical pipeline will take care of the numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d65df8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:53:15.276334Z",
     "iopub.status.busy": "2024-02-20T01:53:15.275894Z",
     "iopub.status.idle": "2024-02-20T01:53:15.281057Z",
     "shell.execute_reply": "2024-02-20T01:53:15.279848Z"
    },
    "papermill": {
     "duration": 0.0277,
     "end_time": "2024-02-20T01:53:15.283507",
     "exception": false,
     "start_time": "2024-02-20T01:53:15.255807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Using ColumnTransformer \n",
    "\n",
    "\n",
    "transformer = ColumnTransformer([(\"num_trans\", num_pipe, num_feat),\n",
    "                            (\"cat_trans\", cat_pipe, cat_feat)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981c0323",
   "metadata": {
    "papermill": {
     "duration": 0.017257,
     "end_time": "2024-02-20T01:53:15.318412",
     "exception": false,
     "start_time": "2024-02-20T01:53:15.301155",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "After finishing the pipelines, we have to apply the transformations to our data. We use “fit.transform” in the “X_train” data to make the model “learn” the transformations and apply “transform” in the “X_test” data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b7b7d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:53:15.356189Z",
     "iopub.status.busy": "2024-02-20T01:53:15.354879Z",
     "iopub.status.idle": "2024-02-20T01:53:16.081793Z",
     "shell.execute_reply": "2024-02-20T01:53:16.080526Z"
    },
    "papermill": {
     "duration": 0.74844,
     "end_time": "2024-02-20T01:53:16.084463",
     "exception": false,
     "start_time": "2024-02-20T01:53:15.336023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/category_encoders/ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "/opt/conda/lib/python3.10/site-packages/category_encoders/ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "/opt/conda/lib/python3.10/site-packages/category_encoders/ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "/opt/conda/lib/python3.10/site-packages/category_encoders/ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "/opt/conda/lib/python3.10/site-packages/category_encoders/ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "/opt/conda/lib/python3.10/site-packages/category_encoders/ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "/opt/conda/lib/python3.10/site-packages/category_encoders/ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "/opt/conda/lib/python3.10/site-packages/category_encoders/ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "/opt/conda/lib/python3.10/site-packages/category_encoders/ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "/opt/conda/lib/python3.10/site-packages/category_encoders/ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n"
     ]
    }
   ],
   "source": [
    "# \".fit_transform\" in train data\"\n",
    "\n",
    "# \".transform\" in test data\"\n",
    "\n",
    "X_train_transformed = transformer.fit_transform(X_train, y_train)\n",
    "X_test_transformed = transformer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ecfe59",
   "metadata": {
    "papermill": {
     "duration": 0.01819,
     "end_time": "2024-02-20T01:53:16.121564",
     "exception": false,
     "start_time": "2024-02-20T01:53:16.103374",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In the next step, we are going to perform a Stratified Cross-Validation to select the best tree-based model we will use. We are going to try three models: LGBMClassifier, XGBoost and XGBoost (booster=”gblinear”). And based on the accuracy, the cross-validation will give the mean and the standard deviation of the performance of each model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d9f49d",
   "metadata": {
    "papermill": {
     "duration": 0.017503,
     "end_time": "2024-02-20T01:53:16.157000",
     "exception": false,
     "start_time": "2024-02-20T01:53:16.139497",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Cross Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6ef273",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:53:16.195777Z",
     "iopub.status.busy": "2024-02-20T01:53:16.195348Z",
     "iopub.status.idle": "2024-02-20T01:53:18.271707Z",
     "shell.execute_reply": "2024-02-20T01:53:18.270339Z"
    },
    "papermill": {
     "duration": 2.099623,
     "end_time": "2024-02-20T01:53:18.274437",
     "exception": false,
     "start_time": "2024-02-20T01:53:16.174814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('xgb', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)), ('xgbgblinear', XGBClassifier(base_score=None, booster='gblinear', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)), ('LGBM', LGBMClassifier())]\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004754 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001305 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001285 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001179 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001256 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "name     results.mean     results.std\n",
      "xgb (0.7875981161695448, 0.012297115244939493)\n",
      "xgbgblinear (0.789795918367347, 0.010914752462021142)\n",
      "LGBM (0.7960753532182104, 0.005903169757288259)\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "models.append((\"xgb\",xgb.XGBClassifier()))\n",
    "models.append((\"xgbgblinear\",xgb.XGBClassifier(booster=\"gblinear\")))\n",
    "models.append((\"LGBM\",LGBMClassifier()))\n",
    "\n",
    "\n",
    "print(models)\n",
    "\n",
    "results = dict()\n",
    "\n",
    "for  name, model in models:\n",
    "    skf = StratifiedKFold(n_splits = 5, random_state=None)\n",
    "    cv_results = cross_val_score(model,X_train_transformed,y_train,cv=skf, scoring=\"accuracy\")\n",
    "    results[name]= (cv_results.mean(), cv_results.std())\n",
    "\n",
    "print(\"name     results.mean     results.std\")\n",
    "\n",
    "for key,value in results.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2d4b03",
   "metadata": {
    "papermill": {
     "duration": 0.018047,
     "end_time": "2024-02-20T01:53:18.310992",
     "exception": false,
     "start_time": "2024-02-20T01:53:18.292945",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can see that LGBMClassifier had the best performance, therefore it will be the model used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e01bf5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:53:18.349498Z",
     "iopub.status.busy": "2024-02-20T01:53:18.349031Z",
     "iopub.status.idle": "2024-02-20T01:53:18.354413Z",
     "shell.execute_reply": "2024-02-20T01:53:18.353238Z"
    },
    "papermill": {
     "duration": 0.027692,
     "end_time": "2024-02-20T01:53:18.356870",
     "exception": false,
     "start_time": "2024-02-20T01:53:18.329178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lgbmc = LGBMClassifier()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5113c3",
   "metadata": {
    "papermill": {
     "duration": 0.018473,
     "end_time": "2024-02-20T01:53:18.395016",
     "exception": false,
     "start_time": "2024-02-20T01:53:18.376543",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "However, the model itself will not be enough to provide great accuracy. Thus, we now have to perform what is called hyperparameter tuning to make the model more precise.\n",
    "\n",
    "We set the parameters we want to test and using sklearn’s GridSearchCV we will obtain the best hyperparameters. GridSearchCV will test the parameters that we want and will show us the combination that has the best performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d7ab2b",
   "metadata": {
    "papermill": {
     "duration": 0.018143,
     "end_time": "2024-02-20T01:53:18.431866",
     "exception": false,
     "start_time": "2024-02-20T01:53:18.413723",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Hyperparameter Tunning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4ed7af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:53:18.471073Z",
     "iopub.status.busy": "2024-02-20T01:53:18.470307Z",
     "iopub.status.idle": "2024-02-20T01:53:18.476293Z",
     "shell.execute_reply": "2024-02-20T01:53:18.475066Z"
    },
    "papermill": {
     "duration": 0.028728,
     "end_time": "2024-02-20T01:53:18.479022",
     "exception": false,
     "start_time": "2024-02-20T01:53:18.450294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "lgbm_params = {\"n_estimators\":[100,200,300], \n",
    "               \"learning_rate\":[0.01,0.05,0.1,0.3],\n",
    "               \"num_leaves\":[20,50,80,100]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68bf218",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:53:18.518827Z",
     "iopub.status.busy": "2024-02-20T01:53:18.518432Z",
     "iopub.status.idle": "2024-02-20T01:53:18.525671Z",
     "shell.execute_reply": "2024-02-20T01:53:18.524639Z"
    },
    "papermill": {
     "duration": 0.029733,
     "end_time": "2024-02-20T01:53:18.528112",
     "exception": false,
     "start_time": "2024-02-20T01:53:18.498379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV (estimator = lgbmc,\n",
    "                            param_grid = lgbm_params,\n",
    "                            n_jobs=-1,\n",
    "                            cv = 5,\n",
    "                            scoring=\"accuracy\",\n",
    "                           error_score='raise')\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb81f25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:53:18.569271Z",
     "iopub.status.busy": "2024-02-20T01:53:18.568873Z",
     "iopub.status.idle": "2024-02-20T01:55:03.840991Z",
     "shell.execute_reply": "2024-02-20T01:55:03.839828Z"
    },
    "papermill": {
     "duration": 105.296379,
     "end_time": "2024-02-20T01:55:03.843814",
     "exception": false,
     "start_time": "2024-02-20T01:53:18.547435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001249 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001271 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001187 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001254 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001277 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001363 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001279 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001166 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001339 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001259 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001263 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001268 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001167 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001244 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001271 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001249 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001179 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001283 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001229 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001276 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001316 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001192 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001271 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001263 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001266 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001283 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001171 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001264 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001243 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001294 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001271 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001165 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001301 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001247 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001246 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001262 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001172 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001238 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001269 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001259 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001415 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001268 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001359 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001333 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001382 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001356 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001267 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001362 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001374 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001397 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001340 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001224 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001321 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001360 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001330 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001336 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001243 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001368 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001343 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001259 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001371 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001174 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001254 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001335 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001342 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001243 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001269 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001266 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001272 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001305 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001190 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001240 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001244 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001280 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001252 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001189 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001266 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001256 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001310 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001299 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001174 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001242 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001241 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001280 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001267 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001196 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001254 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001247 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001242 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001288 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001182 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001267 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001251 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001262 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001293 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001181 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001259 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001270 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001265 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001295 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001169 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001391 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001267 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001244 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001253 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001184 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001278 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001282 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001281 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001259 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001176 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001254 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001283 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001277 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001295 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001170 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001262 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001285 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001292 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001259 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001182 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001242 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001268 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001267 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001256 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001396 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001466 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001948 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001252 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001173 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001278 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001280 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001265 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001281 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001173 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001268 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001257 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001267 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001286 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001248 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001257 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001272 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001276 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001281 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001155 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001295 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001265 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001318 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001328 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001167 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001240 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001281 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001279 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001261 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001170 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001268 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001276 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001280 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001281 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001219 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001282 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001303 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001294 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001170 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001267 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001300 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001270 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001195 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001269 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001262 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001449 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001281 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001190 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001284 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001243 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001275 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001274 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001197 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001287 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001280 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001256 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001261 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001190 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001272 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001420 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001349 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001206 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001328 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001324 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001286 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001319 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001162 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001542 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001581 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001253 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001329 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001171 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001252 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001249 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001262 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001240 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001176 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001239 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001253 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001246 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001173 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001254 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001248 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001263 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001293 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001244 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001292 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001263 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001243 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001294 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001193 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001261 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001461 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001395 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001270 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001161 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001245 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001256 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001264 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001266 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001206 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001288 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2580, number of negative: 2516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001256 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506279 -> initscore=0.025119\n",
      "[LightGBM] [Info] Start training from score 0.025119\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001959 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1382\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001252 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 2581, number of negative: 2515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001332 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1380\n",
      "[LightGBM] [Info] Number of data points in the train set: 5096, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506476 -> initscore=0.025904\n",
      "[LightGBM] [Info] Start training from score 0.025904\n",
      "[LightGBM] [Info] Number of positive: 3226, number of negative: 3144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002238 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1385\n",
      "[LightGBM] [Info] Number of data points in the train set: 6370, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506436 -> initscore=0.025747\n",
      "[LightGBM] [Info] Start training from score 0.025747\n"
     ]
    }
   ],
   "source": [
    "grid_result = grid_search.fit(X_train_transformed, y_train)\n",
    "\n",
    "\n",
    "final_model = lgbmc.set_params(**grid_result.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2d4b99",
   "metadata": {
    "papermill": {
     "duration": 0.041517,
     "end_time": "2024-02-20T01:55:03.927417",
     "exception": false,
     "start_time": "2024-02-20T01:55:03.885900",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "With the best model optimized, we can finally train our model and obtain our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29db42c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:55:04.013955Z",
     "iopub.status.busy": "2024-02-20T01:55:04.013565Z",
     "iopub.status.idle": "2024-02-20T01:55:04.193221Z",
     "shell.execute_reply": "2024-02-20T01:55:04.191683Z"
    },
    "papermill": {
     "duration": 0.226196,
     "end_time": "2024-02-20T01:55:04.195883",
     "exception": false,
     "start_time": "2024-02-20T01:55:03.969687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3226, number of negative: 3144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001584 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1385\n",
      "[LightGBM] [Info] Number of data points in the train set: 6370, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506436 -> initscore=0.025747\n",
      "[LightGBM] [Info] Start training from score 0.025747\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#training the model\n",
    "final_model.fit(X_train_transformed, y_train)\n",
    "\n",
    "\n",
    "#predictions\n",
    "y_pred = final_model.predict(X_test_transformed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ecc50f",
   "metadata": {
    "papermill": {
     "duration": 0.042713,
     "end_time": "2024-02-20T01:55:04.281807",
     "exception": false,
     "start_time": "2024-02-20T01:55:04.239094",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "After obtaining our predictions, we have to test our model using metrics such as recall, precision, f1 score and accuracy. The data frame below shows us some of those metrics and we can conclude that the model is having a great performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75893220",
   "metadata": {
    "papermill": {
     "duration": 0.044166,
     "end_time": "2024-02-20T01:55:04.369176",
     "exception": false,
     "start_time": "2024-02-20T01:55:04.325010",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49972fe0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:55:04.456383Z",
     "iopub.status.busy": "2024-02-20T01:55:04.455964Z",
     "iopub.status.idle": "2024-02-20T01:55:04.475559Z",
     "shell.execute_reply": "2024-02-20T01:55:04.474486Z"
    },
    "papermill": {
     "duration": 0.065647,
     "end_time": "2024-02-20T01:55:04.478034",
     "exception": false,
     "start_time": "2024-02-20T01:55:04.412387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "precision = precision_score(y_pred, y_test)\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "recall = precision_score(y_pred, y_test)\n",
    "f1 = f1_score(y_pred, y_test)\n",
    "\n",
    "score = []\n",
    "score.append((\"precision\", precision))\n",
    "score.append((\"accuracy\",accuracy))\n",
    "score.append((\"recall\",recall))\n",
    "score.append((\"f1\",f1))\n",
    "\n",
    "score= pd.DataFrame(score)\n",
    "score.rename(columns={0: \"Metric\", 1:\"Result\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcbe8bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:55:04.564722Z",
     "iopub.status.busy": "2024-02-20T01:55:04.564311Z",
     "iopub.status.idle": "2024-02-20T01:55:04.574972Z",
     "shell.execute_reply": "2024-02-20T01:55:04.573752Z"
    },
    "papermill": {
     "duration": 0.057112,
     "end_time": "2024-02-20T01:55:04.577224",
     "exception": false,
     "start_time": "2024-02-20T01:55:04.520112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.846958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.811205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.846958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.816308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric    Result\n",
       "0  precision  0.846958\n",
       "1   accuracy  0.811205\n",
       "2     recall  0.846958\n",
       "3         f1  0.816308"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Metrics obtained\n",
    "\n",
    "display(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dde5d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:55:04.663731Z",
     "iopub.status.busy": "2024-02-20T01:55:04.663359Z",
     "iopub.status.idle": "2024-02-20T01:55:04.669428Z",
     "shell.execute_reply": "2024-02-20T01:55:04.668324Z"
    },
    "papermill": {
     "duration": 0.052705,
     "end_time": "2024-02-20T01:55:04.672177",
     "exception": false,
     "start_time": "2024-02-20T01:55:04.619472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8470\n",
      "Accuracy: 0.8112\n",
      "F1_Score: 0.8470\n",
      "Recall: 0.8163\n"
     ]
    }
   ],
   "source": [
    "print(f\"Precision: {score.iloc[0,1]:.4f}\")\n",
    "print(f\"Accuracy: {score.iloc[1,1]:.4f}\")\n",
    "print(f\"F1_Score: {score.iloc[2,1]:.4f}\")\n",
    "print(f\"Recall: {score.iloc[3,1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b0faef",
   "metadata": {
    "papermill": {
     "duration": 0.042437,
     "end_time": "2024-02-20T01:55:04.757453",
     "exception": false,
     "start_time": "2024-02-20T01:55:04.715016",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- Precision: 0.8470\n",
    "- Accuracy: 0.8112\n",
    "- F1_Score: 0.8470\n",
    "- Recall: 0.8163"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9a7cc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:55:04.844912Z",
     "iopub.status.busy": "2024-02-20T01:55:04.844531Z",
     "iopub.status.idle": "2024-02-20T01:55:05.101057Z",
     "shell.execute_reply": "2024-02-20T01:55:05.099998Z"
    },
    "papermill": {
     "duration": 0.303773,
     "end_time": "2024-02-20T01:55:05.103946",
     "exception": false,
     "start_time": "2024-02-20T01:55:04.800173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x78a4fb417e50>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusions_matrix = confusion_matrix(y_pred, y_test)\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "conf_disp = ConfusionMatrixDisplay(confusion_matrix=confusions_matrix)\n",
    "\n",
    "conf_disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d841dc1f",
   "metadata": {
    "papermill": {
     "duration": 0.044182,
     "end_time": "2024-02-20T01:55:05.191493",
     "exception": false,
     "start_time": "2024-02-20T01:55:05.147311",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49401ce8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:55:05.282090Z",
     "iopub.status.busy": "2024-02-20T01:55:05.281686Z",
     "iopub.status.idle": "2024-02-20T01:55:05.311341Z",
     "shell.execute_reply": "2024-02-20T01:55:05.310157Z"
    },
    "papermill": {
     "duration": 0.078609,
     "end_time": "2024-02-20T01:55:05.314160",
     "exception": false,
     "start_time": "2024-02-20T01:55:05.235551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "testecsv = pd.read_csv(\"/kaggle/input/spaceship-titanic/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c4fcb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:55:05.404329Z",
     "iopub.status.busy": "2024-02-20T01:55:05.403916Z",
     "iopub.status.idle": "2024-02-20T01:55:05.427388Z",
     "shell.execute_reply": "2024-02-20T01:55:05.426303Z"
    },
    "papermill": {
     "duration": 0.07186,
     "end_time": "2024-02-20T01:55:05.429729",
     "exception": false,
     "start_time": "2024-02-20T01:55:05.357869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/3/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>27.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nelly Carsoning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/4/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>19.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2823.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Lerome Peckers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>True</td>\n",
       "      <td>C/0/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>31.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sabih Unhearfus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>C/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>38.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6652.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>Meratz Caltilter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/5/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>20.0</td>\n",
       "      <td>False</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Brence Harperez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0027_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/7/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>31.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1615.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Karlen Ricks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0013_01      Earth      True  G/3/S  TRAPPIST-1e  27.0  False   \n",
       "1     0018_01      Earth     False  F/4/S  TRAPPIST-1e  19.0  False   \n",
       "2     0019_01     Europa      True  C/0/S  55 Cancri e  31.0  False   \n",
       "3     0021_01     Europa     False  C/1/S  TRAPPIST-1e  38.0  False   \n",
       "4     0023_01      Earth     False  F/5/S  TRAPPIST-1e  20.0  False   \n",
       "5     0027_01      Earth     False  F/7/P  TRAPPIST-1e  31.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck              Name  \n",
       "0          0.0        0.0           0.0     0.0     0.0   Nelly Carsoning  \n",
       "1          0.0        9.0           0.0  2823.0     0.0    Lerome Peckers  \n",
       "2          0.0        0.0           0.0     0.0     0.0   Sabih Unhearfus  \n",
       "3          0.0     6652.0           0.0   181.0   585.0  Meratz Caltilter  \n",
       "4         10.0        0.0         635.0     0.0     0.0   Brence Harperez  \n",
       "5          0.0     1615.0         263.0   113.0    60.0      Karlen Ricks  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testecsv.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b96a04d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:55:05.520315Z",
     "iopub.status.busy": "2024-02-20T01:55:05.519880Z",
     "iopub.status.idle": "2024-02-20T01:55:05.535510Z",
     "shell.execute_reply": "2024-02-20T01:55:05.534331Z"
    },
    "papermill": {
     "duration": 0.064081,
     "end_time": "2024-02-20T01:55:05.537918",
     "exception": false,
     "start_time": "2024-02-20T01:55:05.473837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "testecsv[[\"cabin_code\",\"id_cabin\",\"cabin_sector\"]] = testecsv[\"Cabin\"].str.split(\"/\", n=2, expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7668cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:55:05.628605Z",
     "iopub.status.busy": "2024-02-20T01:55:05.628179Z",
     "iopub.status.idle": "2024-02-20T01:55:05.635662Z",
     "shell.execute_reply": "2024-02-20T01:55:05.634845Z"
    },
    "papermill": {
     "duration": 0.055148,
     "end_time": "2024-02-20T01:55:05.637855",
     "exception": false,
     "start_time": "2024-02-20T01:55:05.582707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "testecsv.drop(columns=[\"id_cabin\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28be50ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:55:05.726836Z",
     "iopub.status.busy": "2024-02-20T01:55:05.726449Z",
     "iopub.status.idle": "2024-02-20T01:55:05.734532Z",
     "shell.execute_reply": "2024-02-20T01:55:05.733333Z"
    },
    "papermill": {
     "duration": 0.055625,
     "end_time": "2024-02-20T01:55:05.737077",
     "exception": false,
     "start_time": "2024-02-20T01:55:05.681452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_teste = testecsv.drop(columns=[\"PassengerId\",\"Cabin\",\"Name\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531b1437",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:55:05.829288Z",
     "iopub.status.busy": "2024-02-20T01:55:05.828880Z",
     "iopub.status.idle": "2024-02-20T01:55:05.849292Z",
     "shell.execute_reply": "2024-02-20T01:55:05.848115Z"
    },
    "papermill": {
     "duration": 0.068835,
     "end_time": "2024-02-20T01:55:05.851487",
     "exception": false,
     "start_time": "2024-02-20T01:55:05.782652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4277 entries, 0 to 4276\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   PassengerId   4277 non-null   object \n",
      " 1   HomePlanet    4190 non-null   object \n",
      " 2   CryoSleep     4184 non-null   object \n",
      " 3   Cabin         4177 non-null   object \n",
      " 4   Destination   4185 non-null   object \n",
      " 5   Age           4186 non-null   float64\n",
      " 6   VIP           4184 non-null   object \n",
      " 7   RoomService   4195 non-null   float64\n",
      " 8   FoodCourt     4171 non-null   float64\n",
      " 9   ShoppingMall  4179 non-null   float64\n",
      " 10  Spa           4176 non-null   float64\n",
      " 11  VRDeck        4197 non-null   float64\n",
      " 12  Name          4183 non-null   object \n",
      " 13  cabin_code    4177 non-null   object \n",
      " 14  cabin_sector  4177 non-null   object \n",
      "dtypes: float64(6), object(9)\n",
      "memory usage: 501.3+ KB\n"
     ]
    }
   ],
   "source": [
    "testecsv.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ab3396",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:55:05.942444Z",
     "iopub.status.busy": "2024-02-20T01:55:05.941373Z",
     "iopub.status.idle": "2024-02-20T01:55:05.946518Z",
     "shell.execute_reply": "2024-02-20T01:55:05.945600Z"
    },
    "papermill": {
     "duration": 0.053235,
     "end_time": "2024-02-20T01:55:05.949053",
     "exception": false,
     "start_time": "2024-02-20T01:55:05.895818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb48f01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:55:06.040212Z",
     "iopub.status.busy": "2024-02-20T01:55:06.039842Z",
     "iopub.status.idle": "2024-02-20T01:55:06.050077Z",
     "shell.execute_reply": "2024-02-20T01:55:06.049145Z"
    },
    "papermill": {
     "duration": 0.058202,
     "end_time": "2024-02-20T01:55:06.052429",
     "exception": false,
     "start_time": "2024-02-20T01:55:05.994227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X.dropna(subset=[\"cabin_code\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be3b6c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:55:06.145330Z",
     "iopub.status.busy": "2024-02-20T01:55:06.144914Z",
     "iopub.status.idle": "2024-02-20T01:55:07.280945Z",
     "shell.execute_reply": "2024-02-20T01:55:07.279906Z"
    },
    "papermill": {
     "duration": 1.185342,
     "end_time": "2024-02-20T01:55:07.283206",
     "exception": false,
     "start_time": "2024-02-20T01:55:06.097864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/category_encoders/ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "/opt/conda/lib/python3.10/site-packages/category_encoders/ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "/opt/conda/lib/python3.10/site-packages/category_encoders/ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "/opt/conda/lib/python3.10/site-packages/category_encoders/ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "/opt/conda/lib/python3.10/site-packages/category_encoders/ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "/opt/conda/lib/python3.10/site-packages/category_encoders/ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "/opt/conda/lib/python3.10/site-packages/category_encoders/ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "/opt/conda/lib/python3.10/site-packages/category_encoders/ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "/opt/conda/lib/python3.10/site-packages/category_encoders/ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "/opt/conda/lib/python3.10/site-packages/category_encoders/ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n"
     ]
    }
   ],
   "source": [
    "X = transformer.fit_transform(X,y)\n",
    "X_teste = transformer.transform(X_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6503a2ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:55:07.389827Z",
     "iopub.status.busy": "2024-02-20T01:55:07.389458Z",
     "iopub.status.idle": "2024-02-20T01:55:07.605339Z",
     "shell.execute_reply": "2024-02-20T01:55:07.604186Z"
    },
    "papermill": {
     "duration": 0.265224,
     "end_time": "2024-02-20T01:55:07.608065",
     "exception": false,
     "start_time": "2024-02-20T01:55:07.342841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4278, number of negative: 4216\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002108 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1388\n",
      "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503650 -> initscore=0.014599\n",
      "[LightGBM] [Info] Start training from score 0.014599\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(learning_rate=0.05, num_leaves=20)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(learning_rate=0.05, num_leaves=20)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(learning_rate=0.05, num_leaves=20)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8911dafb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:55:07.710203Z",
     "iopub.status.busy": "2024-02-20T01:55:07.709779Z",
     "iopub.status.idle": "2024-02-20T01:55:07.740641Z",
     "shell.execute_reply": "2024-02-20T01:55:07.739512Z"
    },
    "papermill": {
     "duration": 0.082263,
     "end_time": "2024-02-20T01:55:07.743417",
     "exception": false,
     "start_time": "2024-02-20T01:55:07.661154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_predz = model.predict(X_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea58934",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:55:07.837214Z",
     "iopub.status.busy": "2024-02-20T01:55:07.836696Z",
     "iopub.status.idle": "2024-02-20T01:55:07.842688Z",
     "shell.execute_reply": "2024-02-20T01:55:07.841504Z"
    },
    "papermill": {
     "duration": 0.055486,
     "end_time": "2024-02-20T01:55:07.845098",
     "exception": false,
     "start_time": "2024-02-20T01:55:07.789612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "subimisspace = pd.Series(index = testecsv[\"PassengerId\"].values, data = y_predz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc717ab7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:55:07.940437Z",
     "iopub.status.busy": "2024-02-20T01:55:07.940008Z",
     "iopub.status.idle": "2024-02-20T01:55:07.946539Z",
     "shell.execute_reply": "2024-02-20T01:55:07.945335Z"
    },
    "papermill": {
     "duration": 0.05765,
     "end_time": "2024-02-20T01:55:07.948770",
     "exception": false,
     "start_time": "2024-02-20T01:55:07.891120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "subimisspace = subimisspace.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f836d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:55:08.042820Z",
     "iopub.status.busy": "2024-02-20T01:55:08.042437Z",
     "iopub.status.idle": "2024-02-20T01:55:08.055317Z",
     "shell.execute_reply": "2024-02-20T01:55:08.054145Z"
    },
    "papermill": {
     "duration": 0.061957,
     "end_time": "2024-02-20T01:55:08.057512",
     "exception": false,
     "start_time": "2024-02-20T01:55:07.995555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>9266_02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>9269_01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>9271_01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>9273_01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>9277_01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4277 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  0\n",
       "0     0013_01  1\n",
       "1     0018_01  0\n",
       "2     0019_01  1\n",
       "3     0021_01  1\n",
       "4     0023_01  1\n",
       "...       ... ..\n",
       "4272  9266_02  1\n",
       "4273  9269_01  1\n",
       "4274  9271_01  1\n",
       "4275  9273_01  0\n",
       "4276  9277_01  1\n",
       "\n",
       "[4277 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subimisspace = pd.DataFrame(subimisspace)\n",
    "subimisspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67080844",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:55:08.155403Z",
     "iopub.status.busy": "2024-02-20T01:55:08.154871Z",
     "iopub.status.idle": "2024-02-20T01:55:08.162065Z",
     "shell.execute_reply": "2024-02-20T01:55:08.160900Z"
    },
    "papermill": {
     "duration": 0.057605,
     "end_time": "2024-02-20T01:55:08.164397",
     "exception": false,
     "start_time": "2024-02-20T01:55:08.106792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "subimisspace[0]=subimisspace[0].map({1:\"True\", 0:\"False\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6138135",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:55:08.259665Z",
     "iopub.status.busy": "2024-02-20T01:55:08.259178Z",
     "iopub.status.idle": "2024-02-20T01:55:08.265442Z",
     "shell.execute_reply": "2024-02-20T01:55:08.264312Z"
    },
    "papermill": {
     "duration": 0.057086,
     "end_time": "2024-02-20T01:55:08.268400",
     "exception": false,
     "start_time": "2024-02-20T01:55:08.211314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "subimisspace.rename(columns = {\"index\":\"PassengerId\", 0:\"Transported\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb0f901",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:55:08.366044Z",
     "iopub.status.busy": "2024-02-20T01:55:08.365664Z",
     "iopub.status.idle": "2024-02-20T01:55:08.378891Z",
     "shell.execute_reply": "2024-02-20T01:55:08.377958Z"
    },
    "papermill": {
     "duration": 0.063053,
     "end_time": "2024-02-20T01:55:08.381454",
     "exception": false,
     "start_time": "2024-02-20T01:55:08.318401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "subimisspace.to_csv(\"testy.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee210d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:55:08.476600Z",
     "iopub.status.busy": "2024-02-20T01:55:08.475664Z",
     "iopub.status.idle": "2024-02-20T01:55:08.486699Z",
     "shell.execute_reply": "2024-02-20T01:55:08.485683Z"
    },
    "papermill": {
     "duration": 0.060878,
     "end_time": "2024-02-20T01:55:08.488935",
     "exception": false,
     "start_time": "2024-02-20T01:55:08.428057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>9266_02</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>9269_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>9271_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>9273_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>9277_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4277 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId Transported\n",
       "0        0013_01        True\n",
       "1        0018_01       False\n",
       "2        0019_01        True\n",
       "3        0021_01        True\n",
       "4        0023_01        True\n",
       "...          ...         ...\n",
       "4272     9266_02        True\n",
       "4273     9269_01        True\n",
       "4274     9271_01        True\n",
       "4275     9273_01       False\n",
       "4276     9277_01        True\n",
       "\n",
       "[4277 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subimisspace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b231246",
   "metadata": {
    "papermill": {
     "duration": 0.046554,
     "end_time": "2024-02-20T01:55:08.582071",
     "exception": false,
     "start_time": "2024-02-20T01:55:08.535517",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The strategies that I mention in this article led me to a 0.80664 score in the competition and I am sure you can improve my model to achieve an even higher score with your knowledge!\n",
    "\n",
    "If you enjoyed this article, don’t forget to support me or hit me with a follow!\n",
    "\n",
    "See you in the next article!\n",
    "\n",
    "-Fernando Dantas "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 3220602,
     "sourceId": 34377,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30646,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 124.855222,
   "end_time": "2024-02-20T01:55:09.553501",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-20T01:53:04.698279",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
